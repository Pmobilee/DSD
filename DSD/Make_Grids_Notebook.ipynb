{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Appending key for api.wandb.ai to your netrc file: C:\\Users\\Paper/.netrc\n"
     ]
    }
   ],
   "source": [
    "import self_distillation\n",
    "import saving_loading\n",
    "import generate\n",
    "import wandb\n",
    "\n",
    "import util\n",
    "import os\n",
    "import torch\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "cwd = os.getcwd()\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "!wandb login $WANDB_API_KEY\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = \"Cin_256_custom.ipynb\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "steps = 2\n",
    "# prompts = [992,2,  625, 614] # mushroom, shark, gekko (25), tuktuk, kimono\n",
    "# prompts = [538, 576, 616, 649, 719] #church, venice, rope, stonehenge, piggybank\n",
    "# prompts = [538, 616, 649, 719] #church, rope, stonehenge, piggybank\n",
    "\n",
    "prompts = [random.randrange(0, 1000, 1) for i in range(2)]\n",
    "BASE = r\"D:\\BACKUP\\CURRENT DIFFUSION THESIS\"\n",
    "vertical = False\n",
    "\n",
    "\n",
    "\n",
    "if vertical:\n",
    "    shape = (len(prompts), 1)\n",
    "else:\n",
    "    shape = (1, len(prompts))\n",
    "# shape = [1, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "gradient_updates = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'step_sizes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m (\u001b[39m1\u001b[39m \u001b[39m/\u001b[39m np\u001b[39m.\u001b[39mappend(step_sizes[\u001b[39m1\u001b[39m:],\u001b[39m1\u001b[39m))[::\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'step_sizes' is not defined"
     ]
    }
   ],
   "source": [
    "(1 / np.append(step_sizes[1:],1))[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  8   6   4   4   4   4   4   4   4   4   4   4   6   6   6   6   6   8\n",
      "   8   8  10  10  12  14  16  18  22  28  36  56 112 226]\n"
     ]
    }
   ],
   "source": [
    "step_sizes = np.arange(64, 0, -2)\n",
    "update_list = np.exp((1 / np.append(step_sizes[1:],1))[::-1]) / np.sum(np.exp((1 / np.append(step_sizes[1:],1))[::-1]))\n",
    "update_list = (update_list * gradient_updates /  np.append(step_sizes[1:],1)).astype(int) * 2\n",
    "\n",
    "print(update_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2   2   2   4   4   4   4   4   4   4   4   4   6   6   6   6   6   8\n",
      "   8   8  10  10  12  14  16  20  24  30  42  70 182 604]\n"
     ]
    }
   ],
   "source": [
    "step_sizes = np.arange(64, 0, -2)\n",
    "update_list = np.exp(1 / np.append(step_sizes[1:],1)) / np.sum(np.exp(1 / np.append(step_sizes[1:],1)))\n",
    "update_list = ( update_list* gradient_updates /  np.append(step_sizes[1:],1)).astype(int) * 2\n",
    "\n",
    "print(update_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "steps = 64\n",
    "\n",
    "\n",
    "halvings = math.floor(math.log(64)/math.log(2))\n",
    "updates_per_halving = int(gradient_updates / halvings)\n",
    "step_sizes = []\n",
    "for i in range(halvings):\n",
    "    step_sizes.append(int((steps) / (2**i)))\n",
    "update_list = []\n",
    "for i in step_sizes:\n",
    "    update_list.append(int(updates_per_halving / int(i/ 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_list = np.array(update_list)\n",
    "step_sizes = np.array(step_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7912"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(update_list * step_sizes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config_path=f\"{cwd}/models/configs/cin256-v2-custom.yaml\"\n",
    "# original_path=f\"{cwd}/models/cin256_original.ckpt\"\n",
    "# dsdi = f\"{BASE}\\Diffusion_Thesis\\cin_256\\data\\\\trained_models_4000\\\\iterative\\cin_DSDI_64_1e-07_4000\\\\2.pt\"\n",
    "# dsdgl = f\"{BASE}\\Diffusion_Thesis\\cin_256\\data\\\\trained_models_4000\\gradual_linear\\cin_DSDGL_64_1e-07_4000\\\\1.pt\"\n",
    "# dsdn = f\"{BASE}\\Diffusion_Thesis\\cin_256\\data\\\\trained_models_4000\\\\naive\\cin_DSDN_64_1e-07_4000\\\\32.pt\"\n",
    "# dsdgexp = f\"{BASE}\\Diffusion_Thesis\\cin_256\\data\\\\trained_models_4000\\gradual_exp\\cin_DSDGEXP_64_1e-07_4000\\\\1.pt\"\n",
    "# tsd = f\"{BASE}\\Diffusion_Thesis\\cin_256\\data\\\\trained_models_previous\\TSD\\TSD_cin_50k_1e8\\\\16.pt\"\n",
    "\n",
    "\n",
    "config_path=f\"{cwd}/models/configs/cin256-v2-custom copy.yaml\"\n",
    "original_path=f\"{cwd}/models/64x64_diffusion.pt\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from c:\\Code\\Thesis\\DSD/models/64x64_diffusion.pt\n",
      "LatentDiffusion: Running in eps-prediction mode\n",
      "DiffusionWrapper has 400.92 M params.\n",
      "making attention of type 'vanilla' with 512 in_channels\n",
      "Working with z of shape (1, 3, 16, 16) = 768 dimensions.\n",
      "making attention of type 'vanilla' with 512 in_channels\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQAAAAIKCAIAAABDYwbKAAActklEQVR4nO3dYei+7V3X8c/x986MweZNheBqSooyTZKxJ4kgPovlQnsWOQxxVKBitg0ZLqESpB6M7toKEqSpazAGlq4Qx4Rwc3tSLawthVj3A0GsCHE4t/TTg+P4fr7f8/rvidf19y5u3q/t/v+v67zO8zhP/nyP4/h+j9/5Oy/ZkmRZVv0//+3NtnW2yHbvt/c4u5zPe5/dcBrY72XZHz2nOU2loXMp6gs5J77ZM9tOm8DdXNHbEWzLkj7b0Vaxe3aXZP/8/usT6Su7D529bH34EuFKh/II6XPs7FW+9q0c6Gok3YDox7Nx+oB7gB9TQT7vWPYJ9Npem5VPVC9dEZ1jZoe4HdXTjvoixuWNecTyB3Jy4H41tCaRqSFYibvemjF7doaKzIz/M6lJFI9DMoBXmpTsKYN+T02W/epc7Nm/egnwmCfWWlonVt+5tLQk7RBea0mqbctaO573O3t5SUtay5L05ETlsqS19gdLXrL2ofLaf0r2stdXS+fDXz8RXWfXkvd5vdY39mRja619wp4QgHuNRH8UAZ37j3q3h+0a00fNPI7uIT8FbVL+mj8ujdn62q7DU912QZIppqcRdYYGPCRJjj6TEfXEaCc2M0+ZpaqSEb2nW6qw7aTIo9VRCaSESNkx8650IddFafYFxn88Cxl6O/sea40ZsN1Bq9k16tCeLtQtqSaXVAcVwn8pc8ylGphNvKt7Tl9WXwjDP56FkcFkUSYBWcN7atfOjbI1ofmnMoqnhu4m/K+7kyWO52A/us7e8Ed02/NG1uV5mcCDesR+OuBG9MuvqWykE6RKSNQdKMs5lQwlUv+HLOt9czUpGVFCv+eSEeDj0zRtOgAelGjNaJ4k5+Qur6sCtgf2WX76hZ49NEpkjShNg30m98m7GLhkWddW++yZK9SfA3eqAVs3sd1h29l5JytjgO5ek6ngWsz+fEf7SGIy4kv+z9JvZDKZaz629cE66SgnuganA+AhSzue9mK/LS3LWtqL9XtZfllea9WOlrWWtIOyFuW9JK2195HXyqc+LednDIf3/ucyLJ9GdY7dO8jep1h91L6SfZGXJoE/qB5RU/9mXagH2l7GSQ4yKoBR+tb6ZzKkp2cWjVfJhGZtPErwy8xSu84p4qX9x8LLzRNrj+5rR9my9SlJXra8duAt5UevUnKXJS/tcVhrH+n+qfE6+VLNI2udOUI6U8Ja+6fEPqO79561k7Rnofop9O40+UH1Uk9EwEOs6wCbzb3Qckbeb5qrNL1ob32gh3PNFrptZ0C/1gtzy/ywigZ1jT6upmch4AGV2KuHXUlzqB6pundK73OLUB1oz0zd8hm5x2Bfra3TnjLwV56vKjfOZCSdyUenhb1t5V6hXbSIGgAPytJLLUVeF4V6XbOXaWTLn+zPUyukeM2qaVaNpDkXnBddedT5emfZz/v8mRWkWVz0n8C9EqwVZVlrfI060+lCVv2q/hjJSxWmI5Pp1U+5I76XQ2vZX+PUKW/T29Qlbxfjo9YG7uVE2Y6prz+b+8NeERrBO3pMJ/9zQSkHXeK+e8+nulukD2ZxJy3VDJNt6pmJEgAP61E9cZwCNEF4KZOzx9nw5zzj/oTx6+fInUbVW6sXjVCXbf/lyom6yO3V0UqyZlYGPGKsxYyQ/YWRolwTjSRCT+VHdUBCvA4YR3ZVkLkk2VQnSrJeHPvVHDXzImfOAB42gve873J0VMBKqTDy+tGG7X84c/OubaUkLp3W+9JTrkVwqoxRIF/LC106I3A32/ohaYy3Jwy/y9KvzcyjB/NLJSvLH0ud3CWtRqoziuiUtiOtSk+oPrF3/tClTq5ESHX86H/AfTLIzujan9SrMf53Mj7G7ozoSp+YVW/2GcVAau7sq8uL3tyZUJ/rsgNwv+cSRyu/uK76sVfdo7Z//GT919wjp73z/knUvgNO3je+2fkFeO0fcul55Sdasrzy2+46d1vYWsv52drpBM/tS1gV+/ueDNVO3AaBZ8OW9B3jbafp/XklHnqfes3yfDpedrrSBXI+SubT2X9Vt+dMer5T/kqmLGv/SEwpnatmZgLAg2oNZqYcydZHwtNLMkoKdBqYHWQePwvm7hmjxqjMXi/OtaU0o2tPHF3umicBj+nqMlGVobojOksys6ztILzUxJK+ZbbaHUA/l8MT11+TjqabttObekXKb73dAtxvpBwpayv1SGirg7Gr1I7v5DVO7J4DR5JzjfFZT1/G9rFYlJa6XH6l6nK7TeAhHbadn79prPDobSfQXrym+Annb++kpofvrAyNpZ4esGvyyMsqCroXJRlKJpYpqGaQ6rDA3RJiI53IUuNMXWa6McvZaw9KpmT9mi37389U3pa/OAmWuvHMC11xXD7pE59P6AB4RjyieGQwlfzPmnXUA10IV3hnNSefjzF7tDiCPtPOrDnctXb1w5yp+pEs/5Z00zuAPziPoBsh1in53ONa5iaTv/aK61yQT1K4zmRnXEJmGPvPVM4zesioKOqPfzZnLeBuM1WfgSxZX34dseuT9IofGpnT2K0G7b3rT+/d/07NL5kt0u1OF/srGetn4SzpB0/4/2JK39E1gLsl+kbhecllMtiPirQ7SZezY9BWkp4O0UppktfPZZ+5b+dEOWJUx9W95q7A3Z5IPjcbeP9i746pZX9q373w15JnnGf7584Inbd66753YjzCoXJ+SdbPSvnV3Vcurf0lAeeWh7X2w4RWHv2wlm3rT1c1Uk+QOM8V8lp2HlJBD8CDknLMrCQjb4+yJxN6Y4/zyVze33lJj/2qdGcO8r+Us9qWXq15rjGF+OOZm+rcSsR32cwMgEeN0HOHb70YtcFMlrogHYn+tc4dRXOFcbc7Evjqc734U90hH2mcabxhDQiPeyL5fGPReVDVsXYis7+oKGn3zn3OzuvEeD3GpL4qyVo7ncozUbL5PEGlbj219gO09jWcbnYuof76p7s9ryq7l9fuh4segEc9J9ez1nxuiZbywB3vp4L63AS9H/w2InHf7bxrgjXH96Xc81zZ/kn47Xry6Dqd53Qk7RNXD1zy/hKy5XoeXD2P9DzHVPsSeDAQHjGWe/z1I3nP8v5Y//yKRLJGrtNJ/95eB6pSm1oWqgNHsnRZ1MkCazKsej9XgarNT+TygUdkBVTXajN18NlL0jXcq5N0C4nnNND7XY/qNaI66/jBQdXh1rtnD7mW6lm5Be6385D9TEOfNH+doqD22NnLfuedjp/3Hn+5n1x7UicpjzrU2W31zxPWWUzdreXZ584S6051evVn5VntfcbTCnCvWo6prGTkNRnWk6F8aOypy4/Bktnc5E5ZQ1IN9OdVsi2NKWKO9bWTxgW9srbV+M8EgEe5473CMkGcXOQHPaK8InLk+WOltPtG2tuHdnb/7sryndN3QpPMSR3n6gK7F1i7ZwJ3SyDmdQ3XGWx7ZlD3kaTikq03egZu+pG6j+jvW1/TJfJNf1Nq4i4t3O/GSatSYQrAM9L1b+cXmRUypPegnOg7b5P8VLRWcL5l7NG5z0i4khl15lMT0Lg829KPqw+v0zMD4HEzYx8jb8d4FiJPzvFv9a9SMHR2P0b06gwjCxrDfTZ24v/l6j7ljuwa+jsPSqUw6gzgQSNRH9GvkZTMeB5F6liW7DzlbHidR8c55+l8vkvbaxk8Up+cNzt1mdBb6QF41Kw+O9gu4TkKg5sPlNFfr9g7JrATpRXj6nE8CVCP9ek9fU2jovAI+UwdIgXC4yr/10xZRjQm70ioJ+vpEiF9o8Zpj52TFHWx6xG+lVx1p+nZw+NyZj+Sv7m7C3A//4dRT7q7QK+ydFp+TXeqf/SyTWaR0Rd0E+Gzj3T1MdMrzd4zumFPOd0xgIclfLuqPJGuX5n1bNeee5fOVGZozqmhx+iZGt18YMn/Jkf2ROPZxrg8jw5ACYCHZSRWp/5OF0imPpZe5oTQCf0Y5s+ff29UEGf3nxjZVrpOpVjncjr8U2Fnjqg9NC4aeEAy7qcq3h6yLwN394inSto6uvOlUdTWpxonrJ7zmpHspy+MCeCD+30XJM6lvhT/Rng58xxw94YqNUeqXZFbwfwXbqaE0VwXrz2zdH5zqWt7jB8tzU2z0u0aeFTQwEPq975k9S+fWPktmf7lE0v7uwB0DqlbRl2/575WD/XVhs8hdaOoxxcArPoO7fqC7csvw+T16ovcl9LfkO36dXngPk+W134gQ74tftU9xs5viOkEYiJf85cn95/n5uZ9u/LyWvsrL1bmAOnj5zsw6r5mV6dYPffoNL5W3TGtt9el7E61Hx7hN3xr30UN3CuF61x/7wSlF3A00hvrj2aZptrYfkr1aqQ1oxae5UGq3XExVTOMDOladWT7PoBMCA96arUxK0Dn46TzP3ICU/o/Y4f3VwdSknxf8vQqAr6n6+I6hyrdV05eTV0qky5JsuY0qnbgfgnwUarOxaDEXHcJzWG4ly27pSzSyCPQO5Cl9/Q6Zwrs7JHJRpl/1A325Ur6fnoAHnQdUSt36YylUqOKvorQHqdHMCe56X4k/XRvyAKmxib1IaO1OTHNTlG5T2dmwAM65i+xlny/s45ahZdk//Pb2cJjl0wNle9kt86wbk6YPjaP7HQ/s8FN/k8HAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPCHwbJky+dV/rJsy2cn2ZJt1avP7hf7nWzXDvuID+3t+53Pf3v3s+s5x37rNKRczzldtb0P1TjUL/W/FV6OEmUnfrcZsOfF/DRvq6PsmKyQ1iWouwNkvzQgWf6G6lUf8dycznc+/XBd1+yjL/G/Fl52fEIqwZqekOC+HY6rc1RUX7pFzSLpFvYXnbcZyGV9levkI5x7jsnePYf8pv1qVQOS9JmaYYD79fhtd/gnzux3VZbS6UsSpZ+9jsLZpwN7x+9XjNTK1W2uedH8zHNecSVonWR59AvgQQnOy5h+3r3z7CJJHz77Vwp0TeD3R55x3HPIiOWeYfLf6G6n881SoT7py83eH6EL4DGV4ahjf2y/ZPJjdM7RGZ1TAY8xeqRVXTekjXHKcVCXw51M9cdj8gGehRFjl7iskbjHcs9dZg3aac+M+e1/aWyvGUZPjfi5iO5S0g/PFOm8GN1pNgfcaYZx3nW2npy/XnTRqy85Leww/Eejmu486JLBJ+rH+VI917auINxHZxrKjNSZFvCwkXyog62H2kvSsaPyn4xK1Lb9Y53ypyToxKhnAs+B/5raq05zKStGn8q4X/vSBfCQJUtrB9uqjZalpeWldV5nh2V5eVla6wzcS7LWWrK8JFtrSTlYa/eTpaVla8le+4+VsntpN6qz/9I+zb4GW+ucRvu163qXgPs9kWYR7OUd2jodowJtnT8ryFW7ZPvpM7u77I7gdbrCDuN1RvZVXaDmmbVOZ9nRbK0d5CsnWyuj/dLnJOtXtexFEoSHZSmm1xt78bE2eGQoN3lLVnay9LP9i+TqvaY0VoLGhuqBfRHjPL+ccqTrA1v6ma6NgbvNRD6rMbMXXGuDLN7UsZ69oPbqzP261qO0fFPgjs6lm3OMPjjWmUafBO73ZKX8XDvFX94ZzMmzrSVrzZG8usNJ1PerZVsvSn93p0CS15JX7bhsnyynkp219qf2qiJDr91n0r4cyz4VhE46VWdd1urDgPvN9c2sL/ZIXENupzi9pNMTR08X154ylkTHBPCr6t3GCmktmEqy9Kpc1Fee1Ogdo+lKtf5f/avh5WKsXM5EY3/2Ts1Y77Rdsx+oy+hL4pRmVMuY6QWjc7xZOaYXSasYSKo0elvVJIz+eCacMJY/N4vULn8vsTlW6D1iuwNTtn5G9qsudfNNaZHponrLd+82NU8vS+/tOmAUF3V64CFjpbMWIS2ttbyXMvcC5B6fl3bWvXN2Z2E/a/HrROWq3Pzk7+cnBmdF8zSW8sBnkX/XE2ez+rXTel3KvlqnPeABY52lc5m5WZa+aaT8NWr7OjNckhxloN6fvc16vg/tokE1FVyyqZyp0yhfU58xlQCP6EgdCUkVwZ0CaRbJ+93IZEZmk/1nLVFldBfYXXjsHdyXkqO6HMjl1U7fqO4MwN2eUyU89bPXs7a4LJ87GiRJdu13shhlRfNkKqsH7Z3ALPddFsvWOfyT0rllYsfz5Q6M3Vatd67OorRvndiN7bRJYxtwl53Dn7sUcvOPO8uusHQn4ad31Psk7Hb1hV0FrHGPUdUOzk8P+hzL+8ga7NdKZbF7oWcHWnX283MFegAekTTCtn+pkoxkJ53fnLuGRorze/uwFA6dvauWc1IenGRppFaqo3VdXMpR2VX+q5blVydTyxIQC0F4VGfco2Yd+fu1Pj171rYzAyTJPx+l3K1ly+/JYSO6u5wdjXXFcSkZ8up0yb8+ynXgbnu5s9Yce1F03wyR5cta2Txroxqp0slC7HNrdVKX3S3OzaLZpuQ6Z6313PhcOZjPPdRaY8dz3nPJ2hnVOB1wr05Xso6Z8bgWeubksP+uY7NokxSmMyRZr9yfv1m9OjRXPM80UWupY0mpU6KeX84V1NWR/eBZyMK8Ovce2UZlQAm7kZ5rRuh1MbQ+GKfofOiSSqXr1O6XfKjSqlxm2rtsAe5n6S32d1YCP34ANZb039t9I+N06oWbkB2F7xipK2jT9Nlce52upWu4j46jno66x9AB8JgezjNM98Bs27/o3iuzwViFSUjXbkmTutGePtQvK5LPFHCZXbrR21mpewxJEJ6BJDgjN5Gkt1e6PjrI06sySYVO1H9t50HJ2aVLz9LoATPT6avJYbuVv1h97nbQn4kTcJ8xGM9qdEToGNHnIJ4g7ZbGXjNZ0pg7RlWhed79v6/rXU+L3W8s2f+7znTpEsDdLpXlHIufCn/bVj/nNmP7l3ahbEv/6Zr0ZMcK1791Wq/qNunPLAXUp8k1Wn6vX7hMHHQAPCr5/Ex2PIJuJOGXYbuP7vdJcSqrt76y69VZTNTk0JW3L71Nie5qqPrJf5tH0gHwoLG60usvFYkdy+6Qlma41kC/Y/tdCfUe2S3Jv3saHAHdxXb3ht5YWdFPdgU8emRnbsAj+j5Q6dyFWXdyOr9yYnv+kkx+UizVDWr1kKw1fn7r3Fxq5RbScefoefaW52+22Psm0r2Ldpc5P/p1XuQs+2fSL/W/GV5GnltV8e6ntNWjGiRVsFXwZ7g9z2vbb1z3PuSeB9fjJPoG6X3XaXWWuonhtFVnOu35NLqP7ps91+kd55fIxr2pwCNGqZrlmBfUeVHyoZGyJ6HvRL2Xf5Qtb7ItvaqXfpQ1pFlfdAJ0qQvGolLO3018On0GuF+iqNL6uR6TlZgO+dsVSMuf12WrP3q21+ZUCGklhXLCOf8pzWj2weT/e9P70/+Ah/j9s6LNcuZcl3F1iLHwmIxl/zFG6bmWMxdAsxw6auOEe80GNVGM1aexPJX1qVp0eqn+kfDylUjv9RuNMJz7Xcb9ORs4AVyLNK9ImCbs++1NCqSRXul2+8yM9H3Jwjrheun/xfCykqXIOai7ko4db5+szSOzGWVDUhnJ+qpe4UzzNWLXGW/WSPvvxLT1kUtRMo7taYokCI/r7FqqITcTgTKqX+rQjvjKSD6fEXkUvJlFXt+Fre2/3Sdy95BzNZX9//l0k3S42XxnWsBjkpuPZGhEV/WPUfqOvH3k610hZOy35Rc9zpEu02N7H60+etYZnW31/KNZPgMP6TF/ZEOeAZphtwKvZoQ6tHtI6tPs8+Y+Jn2m0x9L/z2Zf19EUp2ZBVmfVZoftTDwgBOV//hEVCK6P9SM8QRwZ0uXEX+O5NeAHzl7VxwZ15M29SmrH9Z1Wtanu4+OVoD7jRRmhl8NsJ2rz4DrUPe1S6gnCKnjtDtWzy229/zQWU73vbqSHx1d7Hyi/2JbXywR/XgGOtLPe/2NZDfXIfbE31j76aFesr81JW3q14ruDPg9QVR/uyQ0XT+PCiNTy37z3Rp1CPCQmWInv66StOIwG0einwOT3M9SuGvm9AFpvE7od4Kl2mFk/h94qke9IEm/0jkT8IhVg/j16T31RUT1bMQdaHmSj32e76N5YN0Olxvf9leb/r7WE/WXnyp3uZ0z97ehyvWtrHlU0ahz57exyvWwIJ6Pjkc8Od8Cdr4qbOm8UcJ1R/+qgD/fmVo3iZ5d62FaewRfFaFL1noin8doVVP7cNeBS+v1kuse0/mtAOfLxM4R56tVz7eFEfl4BvxnpZGRV16S5UxVKvSGSk/s3lrlQ/2ZqmBkT5XIV8JT+bv6II2CoE+qLB/1WXXTPDkQHvSxXmMZ1WZHv/vNZSGzy9TRB1Io15FdLyTLr/qi159mV6l+Vf2p16ayQlX/pwjGM9ADba926geyalMLmR2/M1orfut99usWJf1OJpdLTd2F7Kisz8Gzu1iXFsdEwwyAh/X6TjKQMQrXTnt7r97UkTVDJCXpVKcTnvw1O4kT9jXJXAb4bM1yqPpEiX/gMU8k1VpQWefpy/VrkLbrtw+91tJyfTeeZS2tZS3pJ5aW+0nO/3Ov5OyutfJ053V+CfI02ZWs3e+8d1SeOr3y9dg69bmVr58B7tfLM3PQ70V69Ryhd1yT9qqBs1sXrT2VjCnClVBVSjVrB/VHJ6ma88r52K/tPTv3Au43glxJSa6V6EzNO767JvUf001Mp5x1Ep3uR+9zB/UXajSZT3WVbuoLLlQBj+jaciy8XAvMGdpZxVE6xukvf0JjzN8vvzfziuRvq3j9B0rpLfXpRu+TJP3J2ZL9L28ukC6AZ+bjGfElVSTWuPw3NfMizTTHNx2h3+8Pf/u8/+Ma/atacDpfjftjZqlruSRFfQ19GPCI8zSq82ZVeJ1H9+xvc1znW4tWfkibb4LfdyzUx7ulvX/9NLm//bG+DUn5qvdcgep7mvb2+kL6upjzJU2eXyZZ9TI/DsYjniShyRLLquTk3KawR/P6VrAdx1pe5+u8dg9Y5w+d3rKcvpVv/ZXrgXLnZom6A2Ofy7vRuhfpnGnVc+jOFxGv3KG06ulxwN2enPFey16V3q/uB2e8XqMPdByfMK/kZA/v/rKT5HR8VtayznMN1/J/XEteq75vbz/2rZeP1pkm6ivzXCuzJyNaY7ICHpGC93b5J0VqZ9y1fjOrhZSymq/7QF3azyKTa6lTL2jW1fq+PvY0Zkn/LsVGrzN19QHc6dza7HrGp3RuXHY/g/Nk8nkybu/pk873t8L3t82PE9SXu1cl4T2Y6zw+N8XFnm9WfwPrfuhuvoR+bN3djK+JBwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD8f+L/ApdSXZv6e9eNAAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=256x522>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher, sampler_student = util.create_models(config_path, original_path, student=False)\n",
    "new_image, noise_list, prompt_list = generate.ablation(sampler_student, steps=steps, shape=shape, celeb=False, model_type=\"original\", prompts=prompts)\n",
    "del teacher, sampler_student\n",
    "torch.cuda.empty_cache()\n",
    "original_img = new_image\n",
    "new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher, sampler_student = util.create_models(config_path, original_path, student=False)\n",
    "new_image, noise_list, prompt_list = generate.ablation(sampler_student, steps=64, shape=shape, noise_list = noise_list, celeb=False, model_type=\"original\", prompt_list=prompts)\n",
    "del teacher, sampler_student\n",
    "torch.cuda.empty_cache()\n",
    "original_64_img = new_image\n",
    "new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student, sampler_student, optimizer, scheduler = util.load_trained(dsdgexp, config_path)\n",
    "new_image, _, _ = generate.ablation(sampler_student, steps=steps, shape=shape, celeb=False, model_type=\"DSDGEXP\", noise_list=noise_list, prompt_list=prompts)\n",
    "del optimizer, scheduler, student, sampler_student\n",
    "torch.cuda.empty_cache()\n",
    "dsdgexp_img = new_image\n",
    "new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student, sampler_student, optimizer, scheduler = util.load_trained(dsdi, config_path)\n",
    "new_image, _, _ = generate.ablation(sampler_student, steps=steps, shape=shape, celeb=False, model_type=\"DSDI\", noise_list=noise_list, prompt_list=prompts)\n",
    "del optimizer, scheduler, student, sampler_student\n",
    "torch.cuda.empty_cache()\n",
    "dsdi_img = new_image\n",
    "new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student, sampler_student, optimizer, scheduler = util.load_trained(dsdgl, config_path)\n",
    "new_image, _, _ = generate.ablation(sampler_student, steps=steps, shape=shape, celeb=False, model_type=\"DSDGL\", noise_list=noise_list, prompt_list=prompts)\n",
    "del optimizer, scheduler, student, sampler_student\n",
    "torch.cuda.empty_cache()\n",
    "dsdgl_img = new_image\n",
    "new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student, sampler_student, optimizer, scheduler = util.load_trained(dsdn, config_path)\n",
    "new_image, _, _ = generate.ablation(sampler_student, steps=steps, shape=shape, celeb=False, model_type=\"DSDN\", noise_list=noise_list, prompt_list=prompts)\n",
    "del optimizer, scheduler, student, sampler_student\n",
    "torch.cuda.empty_cache()\n",
    "dsdn_img = new_image\n",
    "new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student, sampler_student, optimizer, scheduler = util.load_trained(tsd, config_path)\n",
    "new_image, _, _ = generate.ablation(sampler_student, steps=steps, shape=shape, celeb=False, model_type=\"TSD\", noise_list=noise_list, prompt_list=prompts)\n",
    "del optimizer, scheduler, student, sampler_student\n",
    "torch.cuda.empty_cache()\n",
    "tsd_img = new_image\n",
    "new_image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final CIN Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_labels = [\"Original 64\", \"Original\", \"TSD\", \"DSDI\", \"DSDN\", \"DSDGL\", \"DSDGEXP\"]\n",
    "grid = generate.create_horizontal_grid(original_64_img, original_img,tsd_img, dsdi_img, dsdn_img,  dsdgl_img, dsdgexp_img, celeb=False, steps=steps, font_size=20, x_labels=x_labels)\n",
    "grid"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CELEB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "import self_distillation\n",
    "import saving_loading\n",
    "import generate\n",
    "import wandb\n",
    "import util\n",
    "import os\n",
    "import torch\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "cwd = os.getcwd()\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "!wandb login 4baa24c4fc6c8eed782cacb721d34977149d4fcb\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = \"Cin_256_custom.ipynb\"\n",
    "\n",
    "\n",
    "steps = 2\n",
    "prompts=None\n",
    "celeb = True\n",
    "\n",
    "vertical = False\n",
    "\n",
    "\n",
    "n = 2\n",
    "if vertical:\n",
    "    shape = (n, 1)\n",
    "else:\n",
    "    shape = (1, n)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CELEB run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path=f\"{cwd}/models/configs/celebahq-ldm-vq-4.yaml\"\n",
    "original_path=f\"{cwd}/models/CelebA.ckpt\"\n",
    "\n",
    "\n",
    "\n",
    "dsdi = f\"{BASE}\\Diffusion_Thesis\\cin_256\\data\\\\trained_models\\iterative\\celeb_DSDI_64_1e-07_4000\\\\8.pt\"\n",
    "dsdgl = f\"{BASE}\\Diffusion_Thesis\\cin_256\\data\\\\trained_models\\gradual_linear\\celeb_DSDGL_64_1e-07_4000\\\\2.pt\"\n",
    "dsdn = f\"{BASE}\\Diffusion_Thesis\\cin_256\\data\\\\trained_models_previous\\\\final_versions\\celeb\\DSDN\\\\32.pt\"\n",
    "dsdgexp = f\"{BASE}\\Diffusion_Thesis\\cin_256\\data\\\\trained_models_4000\\gradual_exp\\celeb_DSDGEXP_64_1e-07_4000\\\\2.pt\"\n",
    "tsd = f\"{BASE}\\Diffusion_Thesis\\cin_256\\data\\\\trained_models_previous\\\\final_versions\\celeb\\TSD\\\\2.pt\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher, sampler_student = util.create_models(config_path, original_path, student=False)\n",
    "new_image, noise_list, prompt_list = generate.ablation(sampler_student, steps=steps, shape=shape, celeb=celeb, model_type=\"original\", prompts=prompts)\n",
    "del teacher, sampler_student\n",
    "torch.cuda.empty_cache()\n",
    "original_img = new_image\n",
    "new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher, sampler_student = util.create_models(config_path, original_path, student=False)\n",
    "new_image, noise_list, prompt_list = generate.ablation(sampler_student, steps=64, shape=shape, noise_list = noise_list, celeb=celeb, model_type=\"original\", prompts=prompts)\n",
    "del teacher, sampler_student\n",
    "torch.cuda.empty_cache()\n",
    "original_64_img = new_image\n",
    "new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student, sampler_student, optimizer, scheduler = util.load_trained(dsdgexp, config_path)\n",
    "new_image, _, _ = generate.ablation(sampler_student, steps=steps, shape=shape, celeb=celeb, model_type=\"DSDGEXP\", noise_list=noise_list, prompt_list=prompts)\n",
    "del optimizer, scheduler, student, sampler_student\n",
    "torch.cuda.empty_cache()\n",
    "dsdgexp_img = new_image\n",
    "new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student, sampler_student, optimizer, scheduler = util.load_trained(dsdi, config_path)\n",
    "new_image, _, _ = generate.ablation(sampler_student, steps=steps, shape=shape, celeb=celeb, model_type=\"DSDI\", noise_list=noise_list, prompt_list=prompts)\n",
    "del optimizer, scheduler, student, sampler_student\n",
    "torch.cuda.empty_cache()\n",
    "dsdi_img = new_image\n",
    "new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student, sampler_student, optimizer, scheduler = util.load_trained(dsdgl, config_path)\n",
    "new_image, _, _ = generate.ablation(sampler_student, steps=steps, shape=shape, celeb=celeb, model_type=\"DSDGL\", noise_list=noise_list, prompt_list=prompts)\n",
    "del optimizer, scheduler, student, sampler_student\n",
    "torch.cuda.empty_cache()\n",
    "dsdgl_img = new_image\n",
    "new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student, sampler_student, optimizer, scheduler = util.load_trained(dsdn, config_path)\n",
    "new_image, _, _ = generate.ablation(sampler_student, steps=steps, shape=shape, celeb=celeb, model_type=\"DSDN\", noise_list=noise_list, prompt_list=prompts)\n",
    "del optimizer, scheduler, student, sampler_student\n",
    "torch.cuda.empty_cache()\n",
    "dsdn_img = new_image\n",
    "new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student, sampler_student, optimizer, scheduler = util.load_trained(tsd, config_path)\n",
    "new_image, _, _ = generate.ablation(sampler_student, steps=steps, shape=shape, celeb=celeb, model_type=\"TSD\", noise_list=noise_list, prompt_list=prompts)\n",
    "del optimizer, scheduler, student, sampler_student\n",
    "torch.cuda.empty_cache()\n",
    "tsd_img = new_image\n",
    "new_image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final CELEB Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_labels = [\"Original 64\", \"Original\", \"TSD\", \"DSDI\", \"DSDN\", \"DSDGL\", \"DSDGEXP\"]\n",
    "# x_labels=None\n",
    "grid = generate.create_horizontal_grid(original_64_img, original_img,tsd_img, dsdi_img, dsdn_img,  dsdgl_img, dsdgexp_img, celeb=celeb, steps=steps, x_labels=x_labels, font_size=20)\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid = generate.create_vertical_grid(original_64_img, original_img,tsd_img, dsdi_img, dsdn_img,  dsdgl_img, dsdgexp_img, celeb=celeb, steps=steps)\n",
    "# grid"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
